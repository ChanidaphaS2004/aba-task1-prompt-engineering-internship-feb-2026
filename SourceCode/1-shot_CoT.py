#Code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏öPromt: One-shot_CoT ‡∏ó‡∏±‡πâ‡∏á Single CoT ‡πÅ‡∏•‡∏∞ Double CoT
# ---------------------------------------------------
# %% [1] @title 1. Library ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Local Path
import os
import json
import re
import pandas as pd
import time
from openai import OpenAI
from collections import Counter
from tqdm import tqdm

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (Local Path)
INPUT_CSV_PATH = "../Data/data_sentiment_no_Off.csv" 
OUTPUT_COMBINED_PATH = "../Result/Sentiment_1-shot-DoubleCoT_1.5b.csv"

print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Library ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Path ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# %% [2] @title 2. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama (Local)
client = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama", 
)

MODEL_NAME = "deepseek-r1:1.5b" 

print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama (Model: {MODEL_NAME}) ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# %% [3] @title 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 
def parse_deepseek_response(full_output):
    # 1. ‡∏™‡∏Å‡∏±‡∏î Thinking Log (<think>...</think>)
    think_match = re.search(r'<think>(.*?)</think>', full_output, re.DOTALL | re.IGNORECASE)
    think_log = think_match.group(1).strip() if think_match else ""
    
    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (‡∏•‡∏ö <think> ‡∏≠‡∏≠‡∏Å)
    clean_text = re.sub(r'<think>.*?</think>', '', full_output, flags=re.DOTALL | re.IGNORECASE).strip()
    
    sentiment = "Unknown"
    raw_json_str = ""
    
    # --- STEP A: ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö JSON ---
    json_match = re.search(r'\{.*\}', clean_text, re.DOTALL)
    
    if json_match:
        raw_json_str = json_match.group().strip()
        
        # ‡∏•‡∏≠‡∏á Parse JSON ‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥‡∏Å‡πà‡∏≠‡∏ô
        try:
            # ‡∏ã‡πà‡∏≠‡∏° JSON ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô "" (Double double quotes) ‡πÄ‡∏õ‡πá‡∏ô " ‡∏≠‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß 
            # (‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏ö‡πà‡∏≠‡∏¢)
            fixed_json = raw_json_str.replace('""', '"')
            data = json.loads(fixed_json)
            res = data.get("sentiment", "")
            if res.lower() in ['positive', 'negative']:
                sentiment = res.capitalize()
        except:
            # ‡∏ñ‡πâ‡∏≤ JSON ‡∏û‡∏±‡∏á ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Regex ‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "sentiment": ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡πâ‡∏≠‡∏ô JSON ‡∏ô‡∏±‡πâ‡∏ô
            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ negative ‡πÉ‡∏ô reasoning_trace ‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö
            fallback_json_match = re.search(r'["\']sentiment["\']\s*:\s*["\']\s*(Positive|Negative)', raw_json_str, re.IGNORECASE)
            if fallback_json_match:
                sentiment = fallback_json_match.group(1).capitalize()

    # --- STEP B: Fallback ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ JSON ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å JSON ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ---
    if sentiment == "Unknown":
        # 1. ‡∏´‡∏≤‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏¥‡∏ö ‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ sentiment: (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏°‡∏µ ** ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá‡πÑ‡∏î‡πâ)
        # Regex ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏≠‡∏á‡∏´‡∏≤ "sentiment" -> ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ : -> ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Positive ‡∏´‡∏£‡∏∑‡∏≠ Negative
        text_pattern = re.search(r'sentiment\s*:\s*\**\s*(Positive|Negative)', clean_text, re.IGNORECASE)
        if text_pattern:
            sentiment = text_pattern.group(1).capitalize()
        else:
            # 2. ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏≠‡∏µ‡∏Å ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Final Conclusion)
            all_matches = re.findall(r'\b(Positive|Negative)\b', clean_text, re.IGNORECASE)
            if all_matches:
                sentiment = all_matches[-1].capitalize()

    # 3. ‡∏£‡∏ß‡∏° Reasoning ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    if raw_json_str:
        final_reasoning = f"THINKING:\n{think_log}\n\nRAW_JSON:\n{raw_json_str}".strip()
    else:
        final_reasoning = f"THINKING:\n{think_log}\n\nPLAIN_TEXT_RESPONSE:\n{clean_text}".strip()
    
    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢
    if not final_reasoning:
        final_reasoning = full_output

    return {
        "sentiment": sentiment,
        "reasoning": final_reasoning
    }

def run_inference(content):
    system_msg = (
        "You are a specialized expert in Sentiment Analysis and Natural Language Understanding."
        "Task: Classify the sentiment of the 'Selected Content' \n"
        "Sentiment Classification Rules:\n"
        "- Positive: The content indicates satisfaction, praise, or a favorable stance.\n"
        "- Negative: The content expresses dissatisfaction, complaints, or unfavorable opinions.\n"

        "## EXAMPLE ##\n"
        "Input Content: 'The bus stop which goes to and from the airport as well as the town center is a minutes walk away and just 2 euros'\n"
        "Output: {\n"
        "  \"reasoning_trace\": \"The content indicates a highly favorable stance by highlighting three key benefits: convenient proximity ('minutes walk away'), high utility/connectivity ('airport as well as the town center'), and excellent value for money ('just 2 euros').\",\n"
        "  \"sentiment\": \"Positive\"\n"
        "}\n\n"

        "## FINAL TASK ##\n"
        "Determine the overall sentiment and choose exactly one value from ['Positive', 'Negative'].\n"
        "Response Format: You must output ONLY a valid JSON object:\n"
        "{"        
        "  \"reasoning_trace\": \"A brief explanation of why this conclusion was reached\",\n"
        "  \"sentiment\": \"Positive | Negative\"\n"
        "}"
    )
    user_msg = f"Input Content: {content}\n\nLet's think step by step." #\n\nLet's think step by step.

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
            temperature=0.6,
            top_p=0.95,
            max_tokens=1024
        )
        return response.choices[0].message.content
    except Exception as e: 
        return f"Error: {str(e)}"

# %% [4] @title 4. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 
df_input = pd.read_csv(INPUT_CSV_PATH)
combined_results = []

print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô {MODEL_NAME} (Majority Vote 3 ‡∏£‡∏≠‡∏ö)...")

for idx, row in tqdm(df_input.iterrows(), total=len(df_input)):
    #topic = row['Topic']
    content = row['Selected Content']
    
    rounds = []
    for r in range(3):
        raw = run_inference(content)
        parsed = parse_deepseek_response(raw)
        rounds.append(parsed)
    
    # Majority Vote
    voted_sentiment = Counter([d['sentiment'] for d in rounds]).most_common(1)[0][0]

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    combined_results.append({
        "ID": row['ID'],
        #"Topic": topic,
        "Selected Content": content,
        "Final_Sentiment": voted_sentiment,
        # Round 1
        "Round1_Reasoning": rounds[0]['reasoning'],
        "Round1_Output": rounds[0]['sentiment'],
        # Round 2
        "Round2_Reasoning": rounds[1]['reasoning'],
        "Round2_Output": rounds[1]['sentiment'],
        # Round 3
        "Round3_Reasoning": rounds[2]['reasoning'],
        "Round3_Output": rounds[2]['sentiment']
    })

    if (idx + 1) % 5 == 0:
        pd.DataFrame(combined_results).to_csv(OUTPUT_COMBINED_PATH, index=False, encoding='utf-8-sig')

pd.DataFrame(combined_results).to_csv(OUTPUT_COMBINED_PATH, index=False, encoding='utf-8-sig')
print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {OUTPUT_COMBINED_PATH}")

# %%
